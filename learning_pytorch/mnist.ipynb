{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16734994",
   "metadata": {},
   "source": [
    "# MNIST With Pytorch: First steps\n",
    "In this notebook, we aim to learn the basics of PyTorch for computer vision using the famous MNIST datasetâ€”an image classification task involving handwritten digits (0 to 9). \n",
    "\n",
    "**We will not focus on architecture choices, but on framework implementation and concepts understanding**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193d8f86",
   "metadata": {},
   "source": [
    "## The Data\n",
    "To pull the data, we need to go through the following steps:\n",
    "1. Download the dataset;\n",
    "2. Divide in training and test data(for further validation);\n",
    "3. Preprocessing;\n",
    "\n",
    "### 1. Download the dataset\n",
    "MNIST is alwready availabel with *torchvision.datasets*. It can be downloaded with the `datasets.MNIST` class. With this class, we can use a handy pipeline that downloads MNIST, saves it at a local directory, defines if it is for training or validation, and apply a preprocessing.\n",
    "\n",
    "### 2. Divide in training and test data\n",
    "It is necessary to divide the dataset into training part and test part to ensure that no test data interferes with training (causing data leakage). To do this, we can use the `DataLoader` class, passing the data, the batch size (for further training) and shuffle to training data. Shuffle is important to garantee that the model will not learn a sequential pattern of the dataset.\n",
    "\n",
    "### 3. Preprocessing\n",
    "With this dataset, we applied a pipeline with `ToTensor()` to transform image data to tensors with values between [0, 1], and `Normalize((0,), (1,))` to normalize with **mean=0** and **std=1** (a commum practice to speed up traning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eecd4443",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Defines transform pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0,), (1,))\n",
    "])\n",
    "\n",
    "# Download and transform\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4b7663",
   "metadata": {},
   "source": [
    "## Visualizing\n",
    "We can use matplotlib to visualize some example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53edaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot images with its lables\n",
    "def show_images(images, labels):\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(10, 2))\n",
    "    for img, label, ax in zip(images, labels, axes):\n",
    "        ax.imshow(img.squeeze(), cmap='gray')\n",
    "        ax.set_title(f'Label: {label}')\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Get a batch of images from the training data loader\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# Display the first 5 images with its labels\n",
    "show_images(images[:5], labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8fe44c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e700a67e",
   "metadata": {},
   "source": [
    "## Defining a Neural Network\n",
    "In Pytorch, a model (in our case a neural network) is defined by a class that inherits `nn.Module`. This class works like a blueprint for a pytorch model and requires at least `__init__()` and `foward()` method implementations.\n",
    "\n",
    "### The constructor\n",
    "In `__init__()` we can define the layers of our model. In this example, we used the following architecture:\n",
    "\n",
    "- **1Âº Layer:** A fully connected layer (defined by `nn.Linear` class) for feature extraction **[784 -> 128]**;<br>\n",
    "- **ReLU:** A activation function for non-linearity **[128 -> 128]**;<br>\n",
    "- **2Âº Layer:** A fully connected layer for final classess features **[128 -> 10]**; <br>\n",
    "- **Softmax:** A activation function to classify the image **[10 -> 10]**.\n",
    "\n",
    "### foward()\n",
    "This method defines the execution order of a inference, from raw image to softmax classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14418f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Input must be a flat tensor\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "model = SimpleNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14141296",
   "metadata": {},
   "source": [
    "## Loss Function and Optmizer\n",
    "At this section we define\n",
    "- Negative Log-Likelihood Loss as our loss function;\n",
    "- Stochastic Gradient Descent as our optmizer\n",
    "\n",
    "`optim.SGD()` receives 3 parameters:\n",
    "- `model.parameters()`, defines that every trainable parameters will be optmized;\n",
    "- `lr=0.01`, defines that the learning step size will be 0.01 (big=-convertion; small=slow);\n",
    "- `momentum=0.9`, defines how much previous gradients affects a current step (0->1 | 0% to 100%). It is important to not stop at a local minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "debcefd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.NLLLoss()  # Negative Log-Likelihood Loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a312719b",
   "metadata": {},
   "source": [
    "## Training \n",
    "For each epoch, a training go through foward pass making infereces, calculates the errors with the loss functions, and adjust itself through backward pass\n",
    "\n",
    "- `optmizer.zero_grad()`: resets the gradients to zero (to avoid accumulation from previous steps);\n",
    "- `model(images)`: generates predictions from the input images;\n",
    "- `criterion(outputs, labels)`: computes the loss by comparing predictions with ground truth labels;\n",
    "- `loss.backward()`: computes gradients via backpropagation;\n",
    "- `optmizer.step()`: updates model weights based on the computed gradients;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7988a5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.47106180781685214\n",
      "Epoch 2, Loss: 0.2348487160678929\n",
      "Epoch 3, Loss: 0.17474408296824517\n",
      "Epoch 4, Loss: 0.13803085089841885\n",
      "Epoch 5, Loss: 0.11493414242678424\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}')\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76151672",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34da64e",
   "metadata": {},
   "source": [
    "For each batch of test data, uses the model to predicts a class. The prediction is the highest probability at the last layer (result of softmax activation), and is compared to the annotation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f9c6bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 96.72%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on test set: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PowerRanger-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
